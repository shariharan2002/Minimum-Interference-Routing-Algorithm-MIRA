{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8542762",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter nbextension enable cellfolding --user --py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "for i in range(1,16):\n",
    "    G.add_node(i)\n",
    "\n",
    "G.add_edge(1,2)\n",
    "G.add_edge(2,5)\n",
    "G.add_edge(5,12)\n",
    "G.add_edge(1,3)\n",
    "G.add_edge(3,6)\n",
    "G.add_edge(6,11)\n",
    "G.add_edge(11,12)\n",
    "G.add_edge(2,3)\n",
    "G.add_edge(2,11)\n",
    "G.add_edge(1,4)\n",
    "G.add_edge(3,4)\n",
    "G.add_edge(3,7)\n",
    "G.add_edge(6,7)\n",
    "G.add_edge(6,10)\n",
    "G.add_edge(11,10)\n",
    "G.add_edge(7,10)\n",
    "G.add_edge(11,13)\n",
    "G.add_edge(10,13)\n",
    "G.add_edge(12,13)\n",
    "G.add_edge(4,9)\n",
    "G.add_edge(7,9)\n",
    "G.add_edge(10,9)\n",
    "G.add_edge(15,9)\n",
    "G.add_edge(8,9)\n",
    "G.add_edge(4,8)\n",
    "G.add_edge(15,14)\n",
    "G.add_edge(10,14)\n",
    "G.add_edge(13,14)\n",
    "for edge in G.edges():\n",
    "    G[edge[0]][edge[1]]['capacity']=12*100\n",
    "G[2][3]['capacity']=48*100\n",
    "G[2][5]['capacity']=48*100\n",
    "G[14][15]['capacity']=48*100\n",
    "G[3][6]['capacity']=48*100\n",
    "G[6][11]['capacity']=48*100\n",
    "G[3][7]['capacity']=48*100\n",
    "G[6][10]['capacity']=48*100\n",
    "G[11][10]['capacity']=48*100\n",
    "G[7][10]['capacity']=48*100\n",
    "IEP=[[1,13],[5,9],[4,2],[5,15],[13,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00aca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# DEMAND=[]\n",
    "# PAIR=[]\n",
    "# for d in range(4000):\n",
    "#     DEMAND.append(random.randint(1,4))\n",
    "#     PAIR.append(random.randint(0,4))\n",
    "\n",
    "import csv\n",
    "with open(r\"C:\\Users\\HARIHARAN SUBRAMANIA\\Desktop\\ACTUAL CN PROJ\\demands.csv\",\"r\") as csv:\n",
    "    f=csv.read()\n",
    "f=f[26:].split(\"\\n\")\n",
    "for i in range(len(f)):\n",
    "    f[i]=f[i].split(\",\")\n",
    "DEMAND=[]\n",
    "PAIR=[]\n",
    "for i in range(4000):\n",
    "    DEMAND.append(int(f[i][2]))\n",
    "    pair=tuple((int(f[i][0]),int(f[i][1])))\n",
    "    for k in range(len(IEP)):\n",
    "        if tuple(IEP[k])==pair:\n",
    "            PAIR.append(k)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f31d2c",
   "metadata": {},
   "source": [
    "##### MIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtracted_graph(G,flow_dict):\n",
    "    for k in flow_dict.keys():\n",
    "        for j in flow_dict[k].keys():\n",
    "            if flow_dict[k][j]>0:\n",
    "                G[k][j]['capacity']-=flow_dict[k][j]\n",
    "    return G.copy()\n",
    "def critical_checker(G,s,d):\n",
    "    critical_links=[]\n",
    "    new_graph=G.copy()\n",
    "    for edge in G.edges():\n",
    "        if new_graph[edge[0]][edge[1]]['capacity']==0:\n",
    "            new_graph.remove_edge(edge[0],edge[1])\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']==0 and edge[1] not in nx.descendants(new_graph,s) and edge[0] not in nx.descendants(new_graph,d) and nx.has_path(new_graph, edge[0],edge[1])==False:\n",
    "            critical_links.append(edge)\n",
    "    return critical_links\n",
    "def critical_value_checker(G,IEP_without_ab,flow_dict_all):\n",
    "    critical_links={}\n",
    "    critical_links_overall={}\n",
    "\n",
    "    for sd in IEP_without_ab:\n",
    "        critical_links_overall[tuple((sd[0],sd[1]))]=[]\n",
    "        critical_links={}\n",
    "        for edge in G.edges():\n",
    "            critical_links[tuple((edge[0],edge[1]))]=0\n",
    "        flow_dict=flow_dict_all[tuple((sd[0],sd[1]))].copy()\n",
    "        for k in flow_dict.keys():\n",
    "            for j in flow_dict[k].keys():\n",
    "                if flow_dict[k][j]>0:\n",
    "                    try:\n",
    "                        critical_links[tuple((k,j))]+=flow_dict[k][j]\n",
    "                    except:\n",
    "                        critical_links[tuple((j,k))]+=flow_dict[k][j]\n",
    "        critical_links_overall[tuple((sd[0],sd[1]))]=critical_links.copy()\n",
    "    return critical_links_overall\n",
    "def non_vital_flow_contributor(G,IEP_without_ab,flow_dict_all):\n",
    "    critical_links={}\n",
    "    for edge in G.edges():\n",
    "        critical_links[tuple((edge[0],edge[1]))]=0\n",
    "\n",
    "    for sd in IEP_without_ab:\n",
    "        flow_dict=flow_dict_all[tuple((sd[0],sd[1]))].copy()\n",
    "        for k in flow_dict.keys():\n",
    "            for j in flow_dict[k].keys():\n",
    "                if flow_dict[k][j]>0:\n",
    "                    try:\n",
    "                        critical_links[tuple((k,j))]+=flow_dict[k][j]\n",
    "                    except:\n",
    "                        critical_links[tuple((j,k))]+=flow_dict[k][j]\n",
    "    return critical_links\n",
    "def MIRA(G,ab,IEP,D):\n",
    "    from networkx.algorithms.flow import preflow_push\n",
    "    #1. Compute Maximum flow values for all (s,d) in P excluding (a,b)\n",
    "    max_flow_calc={}\n",
    "    IEP_without_ab=IEP.copy()\n",
    "    IEP_without_ab.remove(ab)\n",
    "    aaaa=[]\n",
    "    max_flow_dict={}\n",
    "    for sd in IEP_without_ab:\n",
    "        #print(nx.maximum_flow(G,sd[0],sd[1])[0])\n",
    "        max_flow_calc[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[0]\n",
    "        max_flow_dict[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[1]\n",
    "    #2. Compute Critical links C_sd\n",
    "    critical_links={}\n",
    "    for sd in IEP_without_ab:\n",
    "        \n",
    "        critical_links[tuple(sd)]=[]\n",
    "        subt_graph=nx.Graph()\n",
    "        subt_graph=subtracted_graph(G.copy(),max_flow_dict[tuple(sd)])\n",
    "        critical_links[tuple(sd)]=critical_checker(subt_graph.copy(),sd[0],sd[1])\n",
    "    flow_contributor=critical_value_checker(G.copy(),IEP_without_ab,max_flow_dict)\n",
    "    inverse_max_flow_calc={}\n",
    "\n",
    "    for sd in IEP_without_ab:\n",
    "        if max_flow_calc[tuple(sd)]==0:\n",
    "            max_flow_calc[tuple(sd)]=0.000000000001\n",
    "        inverse_max_flow_calc[tuple(sd)]=1/max_flow_calc[tuple(sd)]\n",
    "    #3 Compute the weight of links w(l)\n",
    "    w={}\n",
    "    curr_sum=0\n",
    "    c_length=[]\n",
    "    for c in critical_links.keys():\n",
    "        c_length.append(len(critical_links[c]))\n",
    "    for edge in G.edges:\n",
    "        curr_sum=0\n",
    "        for keys,values in critical_links.items():\n",
    "            if edge in critical_links[keys]:\n",
    "                curr_sum+=inverse_max_flow_calc[keys]#(1/flow_contributor[keys][edge])\n",
    "        w[edge]=curr_sum\n",
    "    non_vital_edge_flow_contributor=non_vital_flow_contributor(G.copy(), IEP_without_ab,max_flow_dict)\n",
    "    import random as random\n",
    "    #print(w)\n",
    "    for keys,values in w.items():\n",
    "        if w[keys]==0:\n",
    "            if non_vital_edge_flow_contributor[keys]!=0:\n",
    "                w[keys]=1/(non_vital_edge_flow_contributor[keys]*1000)\n",
    "            else:\n",
    "                w[keys]=0\n",
    "    #Later on whoseover w(l)=0, choose the minimum no of hops\n",
    "    #4.Eliminate <D edges and form reduced network\n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>=0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=w[edge]/G[edge[0]][edge[1]]['capacity']\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "\n",
    "    return G.copy(),aaaa,format_modified_shortest_path\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e295c3a",
   "metadata": {},
   "source": [
    "##### MHA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98efd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MHA(G,ab,D):\n",
    "    G_temp=G.copy()\n",
    "    G_temp_edge_list=list(G_temp.edges())\n",
    "    for edge in G_temp_edge_list:\n",
    "        if G_temp.get_edge_data(edge[0],edge[1])['capacity']<D:\n",
    "            G_temp.remove_edge(edge[0],edge[1])\n",
    "    for edge in G_temp.edges():\n",
    "        G_temp[edge[0]][edge[1]]['capacity']=1\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(G_temp,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),format_modified_shortest_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1655a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5597c976",
   "metadata": {},
   "source": [
    "##### IMIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008032c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def how_many_paths(G,sd,ij):\n",
    "    all_paths=list(nx.all_simple_paths(G,sd[0],sd[1]))\n",
    "    usage=0\n",
    "    for path in all_paths:\n",
    "        for i in range(len(path)-1):\n",
    "            if (path[i]==ij[0] and path[i+1]==ij[1]) or (path[i]==ij[1] and path[i+1]==ij[0]):\n",
    "                usage+=1\n",
    "    return usage/len(all_paths)\n",
    "\n",
    "def MIRA_1(G,ab,IEP,D):\n",
    "    from networkx.algorithms.flow import preflow_push\n",
    "    #1. Compute Maximum flow values for all (s,d) in P excluding (a,b)\n",
    "    max_flow_calc={}\n",
    "    IEP_without_ab=IEP.copy()\n",
    "    IEP_without_ab.remove(ab)\n",
    "    aaaa=[]\n",
    "    max_flow_dict={}\n",
    "    for sd in IEP_without_ab:\n",
    "        #print(nx.maximum_flow(G,sd[0],sd[1])[0])\n",
    "        max_flow_calc[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[0]\n",
    "        max_flow_dict[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[1]\n",
    "    #2. Compute Critical links C_sd\n",
    "    link_weight={}\n",
    "    for edge in G.edges():\n",
    "        link_weight[edge]=0\n",
    "    for edge in G.edges():\n",
    "        for sd in IEP_without_ab:\n",
    "            maxflow_ratio=max_flow_dict[tuple(sd)][edge[0]][edge[1]]/((max_flow_calc[tuple(sd)]*G[edge[0]][edge[1]]['capacity'])+0.00000000000000000000001)\n",
    "            link_weight[edge]+=maxflow_ratio\n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>=0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=link_weight[edge]\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    \n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),aaaa,format_modified_shortest_path\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e89acf",
   "metadata": {},
   "source": [
    "##### MIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MIH(G,ab,IEP,D,fij,entire_cap,T1=8,T2=4):\n",
    "    from networkx.algorithms.flow import preflow_push\n",
    "    #1. Compute Maximum flow values for all (s,d) in P excluding (a,b)\n",
    "    max_flow_calc={}\n",
    "    max_flow_dict={}\n",
    "    IEP_without_ab=IEP.copy()\n",
    "    IEP_without_ab.remove(ab)\n",
    "    aaaa=[]\n",
    "    for sd in IEP_without_ab:\n",
    "        #print(nx.maximum_flow(G,sd[0],sd[1])[0])\n",
    "        max_flow_calc[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[0]\n",
    "        max_flow_dict[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[1]\n",
    "    #2. Compute Critical links C_sd\n",
    "    critical_links={}\n",
    "#     for sd in IEP_without_ab:\n",
    "#         critical_links[tuple(sd)]=[]\n",
    "#         current_max_flow_graph=preflow_push(G,sd[0],sd[1])\n",
    "#         new_graph=nx.Graph()\n",
    "#         for n_node in current_max_flow_graph.nodes:\n",
    "#             new_graph.add_node(n_node)\n",
    "#         for n_edge in current_max_flow_graph.edges:\n",
    "#             #print(current_max_flow_graph[n_edge[0]][n_edge[1]]['flow'])\n",
    "#             if current_max_flow_graph[n_edge[0]][n_edge[1]]['flow']>0 or current_max_flow_graph[n_edge[1]][n_edge[0]]['flow']>0:\n",
    "#                 new_graph.add_edge(n_edge[0],n_edge[1])\n",
    "#         for edge in G.edges:\n",
    "#             if current_max_flow_graph[edge[0]][edge[1]]['flow']<=0 and nx.has_path(new_graph,edge[0],edge[1])==False and edge[0] not in nx.descendants(new_graph,sd[1]) and edge[1] not in nx.descendants(new_graph,sd[0]):\n",
    "#                 critical_links[tuple(sd)].append(edge)\n",
    "#         aaaa.append(new_graph)\n",
    "    for sd in IEP_without_ab:\n",
    "        \n",
    "        critical_links[tuple(sd)]=[]\n",
    "        subt_graph=nx.Graph()\n",
    "        subt_graph=subtracted_graph(G.copy(),max_flow_dict[tuple(sd)])\n",
    "        critical_links[tuple(sd)]=critical_checker(subt_graph.copy(),sd[0],sd[1])\n",
    "    inverse_max_flow_calc={}\n",
    "    for sd in IEP_without_ab:\n",
    "        inverse_max_flow_calc[tuple(sd)]=1/(0.00000000000001+max_flow_calc[tuple(sd)])\n",
    "    #3 Compute Criticality of each link g(ij)\n",
    "    criticality={}\n",
    "    for edge in G.edges():\n",
    "        criticality[edge]=0\n",
    "    for c in critical_links.keys():\n",
    "        for edge in critical_links[c]:\n",
    "            criticality[edge]=criticality.get(edge,0)+1\n",
    "    #4 Compute max link criticality\n",
    "    beta=-1\n",
    "    for k in criticality.keys():\n",
    "        if criticality[k]>beta:\n",
    "            beta=criticality[k]\n",
    "    #5 Compute link utilization fij\n",
    "    link_utilization={}\n",
    "    for edge in G.edges():\n",
    "        link_utilization[edge]=fij[edge]/entire_cap[edge]          #D/G[edge[0]][edge[1]]['capacity']\n",
    "    #6 Max link utilization alpha\n",
    "    alpha=-1\n",
    "    for k in link_utilization.keys():\n",
    "        if link_utilization[k]>alpha:\n",
    "            alpha=link_utilization[k]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #7 Compute the weight of links w(l)\n",
    "    w={}\n",
    "    for edge in G.edges():\n",
    "        w[edge]=((fij[edge]+D)/entire_cap[edge])+T1*max(0,((fij[edge]+D)/entire_cap[edge])-alpha)+T2*(criticality[edge]/beta)\n",
    "        \n",
    "    \n",
    "    #8.Eliminate <D edges and form reduced network \n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=w[edge]\n",
    "    #9 Use Djikstra algo for shortest path\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        #print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "        try:\n",
    "            fij[tuple((shortest_path[i],shortest_path[i+1]))]+=D\n",
    "        except:\n",
    "            fij[tuple((shortest_path[i+1],shortest_path[i]))]+=D\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),aaaa,format_modified_shortest_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0cf72",
   "metadata": {},
   "source": [
    "##### LIOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f671c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIOA(G, ab, IEP,D,capacity_dict,demand_dict,alpha):\n",
    "    aaaa=[]\n",
    "    \n",
    "    # 1. Set weight of all links\n",
    "    w={}\n",
    "    for edge in G.edges():\n",
    "        w[edge]=0\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']!=0:\n",
    "            w[edge]=((demand_dict[edge])**alpha)/((G[edge[0]][edge[1]]['capacity'])**(1-alpha))\n",
    "        else:\n",
    "            w[edge]=((demand_dict[edge])**alpha)/0.00000000000001\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']<= D:\n",
    "            w[edge]=10**30\n",
    "            \n",
    "    #2.Eliminate <D edges and form reduced network\n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>=0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=w[edge]\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        #print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    \n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "        try:\n",
    "            demand_dict[tuple((shortest_path[i],shortest_path[i+1]))]+=1\n",
    "        except:\n",
    "            demand_dict[tuple((shortest_path[i+1],shortest_path[i]))]+=1\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),aaaa,format_modified_shortest_path\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1bd4fe",
   "metadata": {},
   "source": [
    "##### lLIOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ILIOA(G, ab, IEP,D,capacity_dict,demand_dict,alpha,beta):\n",
    "    aaaa=[]\n",
    "    \n",
    "    # 1. Set weight of all links\n",
    "    w={}\n",
    "    \n",
    "    for edge in G.edges():\n",
    "        w[edge]=0\n",
    "    for edge in G.edges():\n",
    "        \n",
    "        if G[edge[0]][edge[1]]['capacity']!=0:\n",
    "            ul=1-(G[edge[0]][edge[1]]['capacity']/capacity_dict[edge])\n",
    "            w[edge]=(1-ul)*((demand_dict[edge])**beta)/(capacity_dict[edge]**(1-beta))+ ul*((demand_dict[edge]**alpha)/(G[edge[0]][edge[1]]['capacity'])**(1-alpha))\n",
    "        else:\n",
    "            w[edge]=((demand_dict[edge])**alpha)/0.00000000000001\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']<= D:\n",
    "            w[edge]=10**30\n",
    "            \n",
    "    #2.Eliminate <D edges and form reduced network\n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>=0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=w[edge]\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        #print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    \n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "        try:\n",
    "            demand_dict[tuple((shortest_path[i],shortest_path[i+1]))]+=1\n",
    "        except:\n",
    "            demand_dict[tuple((shortest_path[i+1],shortest_path[i]))]+=1\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),aaaa,format_modified_shortest_path\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5f8a2",
   "metadata": {},
   "source": [
    "##### BCRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79400710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCRA(G, ab, IEP,D,capacity_dict):\n",
    "    aaaa=[]\n",
    "    \n",
    "    # 1. Find Load on links\n",
    "    load={}\n",
    "    for edge in G.edges():\n",
    "        load[edge]=G[edge[0]][edge[1]]['capacity']/capacity_dict[edge]\n",
    "    # 2.Find cost of links\n",
    "    cost={}\n",
    "    for edge in G.edges():\n",
    "        cost[edge]=10**8/(capacity_dict[edge])\n",
    "    # 3. Find weight of edge\n",
    "    w={}\n",
    "    for edge in G.edges():\n",
    "        w[edge]=0\n",
    "    for edge in G.edges():\n",
    "        w[edge]=cost[edge]+load[edge]+1\n",
    "            \n",
    "    #2.Eliminate <D edges and form reduced network\n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>=0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=w[edge]\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    \n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),aaaa,format_modified_shortest_path\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56524035",
   "metadata": {},
   "source": [
    "##### RNLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNLC(G, ab, IEP,D,C):\n",
    "    aaaa=[]\n",
    "    # 1. Set weight of all links\n",
    "    current_residual_capacity=0\n",
    "    for edge in G.edges():\n",
    "        current_residual_capacity+=G[edge[0]][edge[1]]['capacity']\n",
    "    w={}\n",
    "    for edge in G.edges():\n",
    "        w[edge]=0\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']!=0:\n",
    "            w[edge]=(current_residual_capacity/G[edge[0]][edge[1]]['capacity'])+C\n",
    "\n",
    "    #2.Eliminate <D edges and form reduced network\n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>=0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=w[edge]\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        #print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    \n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),aaaa,format_modified_shortest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8846b",
   "metadata": {},
   "source": [
    "##### MAX RC MIN F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a76900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCF(G, ab, IEP,D,capacity_dict,demand_dict):\n",
    "    aaaa=[]\n",
    "    \n",
    "    # 1. Set weight of all links\n",
    "    w={}\n",
    "    \n",
    "    for edge in G.edges():\n",
    "        w[edge]=0\n",
    "    for edge in G.edges():\n",
    "        w[edge]=demand_dict[edge]/((capacity_dict[edge]*G[edge[0]][edge[1]]['capacity'])+0.0000000000000001)\n",
    "    #2.Eliminate <D edges and form reduced network\n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>=0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=w[edge]\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    \n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "        try:\n",
    "            demand_dict[tuple((shortest_path[i],shortest_path[i+1]))]+=1\n",
    "        except:\n",
    "            demand_dict[tuple((shortest_path[i+1],shortest_path[i]))]+=1\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),aaaa,format_modified_shortest_path\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba9c970",
   "metadata": {},
   "source": [
    "##### NMIH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91966d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def critical_value_checker(G,IEP_without_ab,flow_dict_all):\n",
    "    critical_links={}\n",
    "    critical_links_overall={}\n",
    "\n",
    "    for sd in IEP_without_ab:\n",
    "        critical_links_overall[tuple((sd[0],sd[1]))]=[]\n",
    "        critical_links={}\n",
    "        for edge in G.edges():\n",
    "            critical_links[tuple((edge[0],edge[1]))]=0\n",
    "        flow_dict=flow_dict_all[tuple((sd[0],sd[1]))].copy()\n",
    "        for k in flow_dict.keys():\n",
    "            for j in flow_dict[k].keys():\n",
    "                if flow_dict[k][j]>0:\n",
    "                    try:\n",
    "                        critical_links[tuple((k,j))]+=flow_dict[k][j]\n",
    "                    except:\n",
    "                        critical_links[tuple((j,k))]+=flow_dict[k][j]\n",
    "        critical_links_overall[tuple((sd[0],sd[1]))]=critical_links.copy()\n",
    "    return critical_links_overall\n",
    "\n",
    "\n",
    "def NMIH(G,ab,IEP,D,entire_cap,T1=8,T2=4):\n",
    "    from networkx.algorithms.flow import preflow_push\n",
    "    #1. Compute Maximum flow values for all (s,d) in P excluding (a,b)\n",
    "    max_flow_calc={}\n",
    "    max_flow_dict={}\n",
    "    IEP_without_ab=IEP.copy()\n",
    "    IEP_without_ab.remove(ab)\n",
    "    aaaa=[]\n",
    "    for sd in IEP:\n",
    "        #print(nx.maximum_flow(G,sd[0],sd[1])[0])\n",
    "        max_flow_calc[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[0]\n",
    "        max_flow_dict[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[1]\n",
    "    #2. Compute Critical links C_sd\n",
    "    critical_values={}\n",
    "    critical_values=critical_value_checker(G.copy(),IEP,max_flow_dict)\n",
    "    alphasd={}\n",
    "    for sd in IEP:\n",
    "        alphasd[tuple(sd)]=1/max_flow_calc[tuple(sd)]\n",
    "    \n",
    "\n",
    "    w={}\n",
    "    for edge in G.edges():\n",
    "        w[edge]=T1+T2*((entire_cap[edge]-G[edge[0]][edge[1]]['capacity'])/entire_cap[edge])\n",
    "        s=0\n",
    "        for sd in IEP_without_ab:\n",
    "            s+=(alphasd[tuple(sd)]*critical_values[tuple(sd)][edge])\n",
    "        s/(D+(alphasd[tuple(ab)]*critical_values[tuple(ab)][edge]))\n",
    "        w[edge]+=s\n",
    "        \n",
    "    \n",
    "    #8.Eliminate <D edges and form reduced network \n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=w[edge]\n",
    "    #9 Use Djikstra algo for shortest path\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        #print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),aaaa,format_modified_shortest_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc0310",
   "metadata": {},
   "source": [
    "##### LEX MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtracted_graph(G,flow_dict):\n",
    "    for k in flow_dict.keys():\n",
    "        for j in flow_dict[k].keys():\n",
    "            if flow_dict[k][j]>0:\n",
    "                G[k][j]['capacity']-=flow_dict[k][j]\n",
    "    return G.copy()\n",
    "def critical_checker_LEX(G,s,d,delta):\n",
    "    critical_links=[]\n",
    "    new_graph=G.copy()\n",
    "    for edge in G.edges():\n",
    "        if new_graph[edge[0]][edge[1]]['capacity']==0:\n",
    "            new_graph.remove_edge(edge[0],edge[1])\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']<delta:\n",
    "            new_new_graph=nx.Graph()\n",
    "            for node in new_graph.nodes():\n",
    "                new_new_graph.add_node(node)\n",
    "            for edge in new_graph.edges():\n",
    "                if delta-new_graph[edge[0]][edge[1]]['capacity']>=0:\n",
    "                    new_new_graph.add_edge(edge[0],edge[1])\n",
    "            if nx.has_path(new_graph, edge[0],edge[1])==False:\n",
    "                critical_links.append(edge)\n",
    "    return critical_links\n",
    "def critical_value_checker(G,IEP_without_ab,flow_dict_all):\n",
    "    critical_links={}\n",
    "    critical_links_overall={}\n",
    "\n",
    "    for sd in IEP_without_ab:\n",
    "        critical_links_overall[tuple((sd[0],sd[1]))]=[]\n",
    "        critical_links={}\n",
    "        for edge in G.edges():\n",
    "            critical_links[tuple((edge[0],edge[1]))]=0\n",
    "        flow_dict=flow_dict_all[tuple((sd[0],sd[1]))].copy()\n",
    "        for k in flow_dict.keys():\n",
    "            for j in flow_dict[k].keys():\n",
    "                if flow_dict[k][j]>0:\n",
    "                    try:\n",
    "                        critical_links[tuple((k,j))]+=flow_dict[k][j]\n",
    "                    except:\n",
    "                        critical_links[tuple((j,k))]+=flow_dict[k][j]\n",
    "        critical_links_overall[tuple((sd[0],sd[1]))]=critical_links.copy()\n",
    "    return critical_links_overall\n",
    "def non_vital_flow_contributor(G,IEP_without_ab,flow_dict_all):\n",
    "    critical_links={}\n",
    "    for edge in G.edges():\n",
    "        critical_links[tuple((edge[0],edge[1]))]=0\n",
    "\n",
    "    for sd in IEP_without_ab:\n",
    "        flow_dict=flow_dict_all[tuple((sd[0],sd[1]))].copy()\n",
    "        for k in flow_dict.keys():\n",
    "            for j in flow_dict[k].keys():\n",
    "                if flow_dict[k][j]>0:\n",
    "                    try:\n",
    "                        critical_links[tuple((k,j))]+=flow_dict[k][j]\n",
    "                    except:\n",
    "                        critical_links[tuple((j,k))]+=flow_dict[k][j]\n",
    "    return critical_links\n",
    "\n",
    "def LEXMAX(G,ab,IEP,D,delta):\n",
    "    from networkx.algorithms.flow import preflow_push\n",
    "    #1. Compute Maximum flow values for all (s,d) in P excluding (a,b)\n",
    "    max_flow_calc={}\n",
    "    IEP_without_ab=IEP.copy()\n",
    "    IEP_without_ab.remove(ab)\n",
    "    aaaa=[]\n",
    "    max_flow_dict={}\n",
    "    for sd in IEP:\n",
    "        #print(nx.maximum_flow(G,sd[0],sd[1])[0])\n",
    "        max_flow_calc[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[0]\n",
    "        max_flow_dict[tuple(sd)]=nx.maximum_flow(G,sd[0],sd[1])[1]\n",
    "    #2. Compute Critical links C_sd\n",
    "    critical_links={}\n",
    "    for sd in IEP:\n",
    "        \n",
    "        critical_links[tuple(sd)]=[]\n",
    "        subt_graph=nx.Graph()\n",
    "        subt_graph=subtracted_graph(G.copy(),max_flow_dict[tuple(sd)])\n",
    "        critical_links[tuple(sd)]=critical_checker_LEX(subt_graph.copy(),sd[0],sd[1],delta)\n",
    "    flow_contributor=critical_value_checker(G.copy(),IEP_without_ab,max_flow_dict)\n",
    "    \n",
    "    \n",
    "    #3 Order IEP via maxflow values\n",
    "    max_flow_sorted=sorted(max_flow_calc.items(), key=lambda kv:(kv[1]))\n",
    "    inverse_max_flow_calc={}\n",
    "    for sd in IEP_without_ab:\n",
    "        if max_flow_calc[tuple(sd)]==0:\n",
    "            max_flow_calc[tuple(sd)]=0.000000000001\n",
    "        inverse_max_flow_calc[tuple(sd)]=1/max_flow_calc[tuple(sd)]\n",
    "    #3 Compute the weight of links w(l)\n",
    "    w={}\n",
    "    curr_sum=0\n",
    "    c_length=[]\n",
    "    for c in critical_links.keys():\n",
    "        c_length.append(len(critical_links[c]))\n",
    "    p=0\n",
    "    for edge in G.edges:\n",
    "        curr_sum=0\n",
    "        p=len(IEP)\n",
    "        i=0\n",
    "        for keys,values in max_flow_sorted:\n",
    "            i+=1\n",
    "            if i!=p:\n",
    "                if edge in critical_links[keys]:\n",
    "                    curr_sum+=((len(G.edges()))*D(1+(len(G.edges())*D)))**(p-i-1)#(1/flow_contributor[keys][edge])\n",
    "            else:\n",
    "                curr_sum+=1\n",
    "        w[edge]=curr_sum\n",
    "    non_vital_edge_flow_contributor=non_vital_flow_contributor(G.copy(), IEP_without_ab,max_flow_dict)\n",
    "    import random as random\n",
    "    #print(w)\n",
    "    for keys,values in w.items():\n",
    "        if w[keys]==0:\n",
    "            if non_vital_edge_flow_contributor[keys]!=0:\n",
    "                w[keys]=1/(non_vital_edge_flow_contributor[keys]*1000)\n",
    "            else:\n",
    "                w[keys]=0\n",
    "    #Later on whoseover w(l)=0, choose the minimum no of hops\n",
    "    #4.Eliminate <D edges and form reduced network\n",
    "    new_G=nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        new_G.add_node(node)\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']-D>=0:\n",
    "            new_G.add_edge(edge[0],edge[1])\n",
    "            new_G[edge[0]][edge[1]]['capacity']=w[edge]/G[edge[0]][edge[1]]['capacity']\n",
    "    try:\n",
    "        shortest_path=nx.shortest_path(new_G,ab[0],ab[1],weight='capacity')\n",
    "    except:\n",
    "        print(\"No Path Found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        G[shortest_path[i]][shortest_path[i+1]]['capacity']-=D\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(shortest_path)-1):\n",
    "        l=[shortest_path[i],shortest_path[i+1]]\n",
    "        format_modified_shortest_path.append(l)\n",
    "#     for edge in G.edges():\n",
    "#         print(G.get_edge_data(edge[0],edge[1])['capacity'])\n",
    "    return G.copy(),aaaa,format_modified_shortest_path\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e768d",
   "metadata": {},
   "source": [
    "##### SWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SWP(G,ab,D):\n",
    "    new_G=G.copy()\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']<D:\n",
    "            new_G.remove_edge(edge[0],edge[1])\n",
    "    all_paths=list(nx.all_simple_paths(new_G,ab[0],ab[1]))\n",
    "    if len(all_paths)==0:\n",
    "        print(\"No Path found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    all_paths_dict={}\n",
    "    ctr=0\n",
    "    for path in all_paths:\n",
    "        all_paths_dict[ctr]=10000000000000000\n",
    "        for i in range(len(path)-1):\n",
    "            if new_G[path[i]][path[i+1]]['capacity']<all_paths_dict[ctr]:\n",
    "                all_paths_dict[ctr]=new_G[path[i]][path[i+1]]['capacity']\n",
    "        ctr+=1\n",
    "    max_value=0\n",
    "    max_key=0\n",
    "    new_path_list={}\n",
    "    for keys,values in all_paths_dict.items():\n",
    "        if all_paths_dict[keys]>max_value:\n",
    "            max_value=all_paths_dict[keys]\n",
    "    for keys,values in all_paths_dict.items():\n",
    "        if all_paths_dict[keys]==max_value:\n",
    "            new_path_list[keys]=all_paths[keys].copy()\n",
    "    min_value=1000000000000\n",
    "    min_key=0\n",
    "    for keys,values in new_path_list.items():\n",
    "        if len(new_path_list[keys])<min_value:\n",
    "            min_value=len(new_path_list[keys])\n",
    "            min_key=keys\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(all_paths[min_key])-1):\n",
    "        l=tuple((all_paths[min_key][i],all_paths[min_key][i+1]))\n",
    "        G[l[0]][l[1]]['capacity']-=D\n",
    "        format_modified_shortest_path.append(l)\n",
    "    return G.copy(),0,format_modified_shortest_path\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07daa08",
   "metadata": {},
   "source": [
    "##### WSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407602e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WSP(G,ab,D):\n",
    "    new_G=G.copy()\n",
    "    for edge in G.edges():\n",
    "        if G[edge[0]][edge[1]]['capacity']<D:\n",
    "            new_G.remove_edge(edge[0],edge[1])\n",
    "    all_paths=list(nx.all_simple_paths(new_G,ab[0],ab[1]))\n",
    "    if len(all_paths)==0:\n",
    "        print(\"No Path found from\",ab[0],\"to\",ab[1])\n",
    "        return G.copy(),0,0\n",
    "    all_paths_dict={}\n",
    "    ctr=0\n",
    "    for path in all_paths:\n",
    "        all_paths_dict[ctr]=len(path)\n",
    "        ctr+=1\n",
    "    min_value=1000000000000000\n",
    "    min_key=0\n",
    "    new_path_list={}\n",
    "    for keys,values in all_paths_dict.items():\n",
    "        if all_paths_dict[keys]<min_value:\n",
    "            min_value=all_paths_dict[keys]\n",
    "    for keys,values in all_paths_dict.items():\n",
    "        if all_paths_dict[keys]==min_value:\n",
    "            new_path_list[keys]=all_paths[keys].copy()\n",
    "    max_value=0\n",
    "    for keys,values in new_path_list.items():\n",
    "        max_value=0\n",
    "        for i in range(len(new_path_list[keys])-1):\n",
    "            if new_G[new_path_list[keys][i]][new_path_list[keys][i+1]]['capacity']>max_value:\n",
    "                max_value=new_G[new_path_list[keys][i]][new_path_list[keys][i+1]]['capacity']\n",
    "        new_path_list[keys]=max_value\n",
    "    new_path_list_sorted= sorted(new_path_list.items(), key=lambda kv:(kv[1]),reverse=True)\n",
    "    format_modified_shortest_path=[]\n",
    "    for i in range(len(all_paths[new_path_list_sorted[0][0]])-1):\n",
    "        l=tuple((all_paths[min_key][i],all_paths[min_key][i+1]))\n",
    "        G[l[0]][l[1]]['capacity']-=D\n",
    "        format_modified_shortest_path.append(l)\n",
    "    return G.copy(),0,format_modified_shortest_path\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0a820",
   "metadata": {},
   "source": [
    "##### Plotting FUnctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_decrease_on_links(flow_tracker,R,G):\n",
    "    for edge in G.edges():\n",
    "        try:\n",
    "            flow_tracker[tuple(edge)].append(G[edge[0]][edge[1]]['capacity'])\n",
    "        except:\n",
    "            flow_tracker[tuple((edge[1],edge[0]))].append(G[edge[0]][edge[1]]['capacity'])\n",
    "\n",
    "def link_usage(link_user,link_user_by_IEP,R,G,iep):\n",
    "    for e in R:\n",
    "        try:\n",
    "            link_user[tuple(e)]+=1\n",
    "        except:\n",
    "            link_user[tuple((e[1],e[0]))]+=1\n",
    "        try:\n",
    "            link_user_by_IEP[tuple(iep)][tuple(e)]+=1\n",
    "        except:\n",
    "            link_user_by_IEP[tuple(iep)][tuple((e[1],e[0]))]+=1\n",
    "    \n",
    "        \n",
    "def link_user_plotter(link_user):\n",
    "    link_string_list=[]\n",
    "    for l in link_user.keys():\n",
    "        link_string_list.append(str(tuple(l)))\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.bar(link_string_list,link_user.values())\n",
    "    plt.xlabel(\"Links\")\n",
    "    plt.ylabel(\"Usage Frequency\")\n",
    "def link_user_by_IEP_plotter(link_user_by_IEP):\n",
    "    fig,axis=plt.subplots(5,1,figsize=(20,20))\n",
    "    link_string_list=[]\n",
    "    temp=list(link_user_by_IEP.keys())[0]\n",
    "    for l in link_user_by_IEP[temp]:\n",
    "        link_string_list.append(str(tuple(l)))\n",
    "    i=0\n",
    "    for keys in link_user_by_IEP.keys():\n",
    "        #print(len(link_string_list),len(link_user_by_IEP[keys]))\n",
    "        axis[i].plot(link_string_list,link_user_by_IEP[keys].values())\n",
    "        axis[i].legend([str(keys)])\n",
    "        axis[i].set(ylabel=\"Frequency\",xlabel=\"Links\")\n",
    "        i+=1\n",
    "    fig.savefig('link_usage_by_IEP.jpg', bbox_inches='tight')\n",
    "#     plt.figure(figsize=(25,8))\n",
    "#     plt.bar(link_string_list,link_user.values())\n",
    "#     plt.xlabel(\"Links\")\n",
    "#     plt.ylabel(\"Usage Frequency\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def flow_tracker_plotter(dictionary):\n",
    "    plt.figure(figsize=(50,50))\n",
    "    figure, axis = plt.subplots(4, 7,figsize=(25,10),sharex=True,sharey=True)\n",
    "    figure.text(0.5, 0.04, 'Instance', ha='center')\n",
    "    figure.text(0.04, 0.5, 'Flow', va='center', rotation='vertical')\n",
    "    r,c=0,0\n",
    "    for keys,values in dictionary.items():\n",
    "        axis[r,c].plot(range(len(dictionary[keys])),dictionary[keys])\n",
    "        axis[r,c].legend([str(keys)],fontsize=12)\n",
    "\n",
    "        c+=1\n",
    "        if c%7==0:\n",
    "            r+=1\n",
    "            c=0\n",
    "def rejection_plotter(rejection,IEP,PAIR):\n",
    "    demand_by_IEP={}\n",
    "    for iep in IEP:\n",
    "        demand_by_IEP[tuple(iep)]=0\n",
    "    for p in PAIR:\n",
    "        demand_by_IEP[tuple(IEP[p])]+=1\n",
    "    accepted={}\n",
    "    for iep in IEP:\n",
    "        accepted[tuple(iep)]=demand_by_IEP[tuple(iep)]-rejection[tuple(iep)]\n",
    "    IEP_string_list=[]\n",
    "    plt.figure(figsize=(50,50))\n",
    "    figure, axis = plt.subplots(1, 3,figsize=(15,5))\n",
    "    #figure.text(0.5, 0.04, 'Instance', ha='center')\n",
    "    #figure.text(0.04, 0.5, 'Flow', va='center', rotation='vertical')\n",
    "    for iep in IEP:\n",
    "        IEP_string_list.append(str(tuple(iep)))\n",
    "\n",
    "    axis[0].bar(IEP_string_list,demand_by_IEP.values())\n",
    "    axis[1].bar(IEP_string_list,accepted.values())\n",
    "    axis[2].bar(IEP_string_list,rejection.values())\n",
    "    axis[0].set(xlabel=\"Ingress-Egress Pair\",ylabel=\" Total Demands\")\n",
    "    axis[1].set(xlabel=\"Ingress-Egress Pair\",ylabel=\"Accepted Demands\")\n",
    "    axis[2].set(xlabel=\"Ingress-Egress Pair\",ylabel=\"Rejected Demands\")\n",
    "        \n",
    "def path_length_plotter(path_length,IEP):\n",
    "    iep_string_list=[]\n",
    "    for iep in IEP:\n",
    "        iep_string_list.append(str(tuple(iep)))\n",
    "    plt.bar(iep_string_list,path_length.values())\n",
    "    plt.xlabel(\"Ingress Egree Pairs\")\n",
    "    plt.ylabel(\"Average Path Length\")\n",
    "\n",
    "\n",
    "def max_flow_decrease(G,max_flow_tracker, IEP):\n",
    "    for iep in IEP:\n",
    "        max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "def max_flow_decrease_plotter(max_flow_tracker,IEP):\n",
    "    \n",
    "    #fig,axis=plt.subplots(1,5,figsize=(20,5))\n",
    "    i=0\n",
    "    plt.figure(figsize=(10,5))\n",
    "    IEP_string_list=[]\n",
    "    for iep in IEP:\n",
    "        IEP_string_list.append(str(tuple(iep)))\n",
    "    for iep in IEP:\n",
    "        plt.plot(list(range(4001)),max_flow_tracker[tuple(iep)])\n",
    "        plt.legend(IEP_string_list)\n",
    "        plt.xlabel(\"Demand Instance\")\n",
    "        plt.ylabel(\"MaxFlow Values\")\n",
    "#         axis[i].plot(list(range(4001)),max_flow_tracker[tuple(iep)])\n",
    "#         axis[i].set(xlabel=\"Demand Instance\",ylabel=\"MaxFlow Value\")\n",
    "#         axis[i].legend(str(tuple(iep)))\n",
    "    \n",
    "        i+=1\n",
    "def router_traversal(node_frequency,R):\n",
    "    distinct=[]\n",
    "    for r in R:\n",
    "        if r[0] not in distinct:\n",
    "            distinct.append(r[0])\n",
    "        if r[1] not in distinct:\n",
    "            distinct.append(r[1])\n",
    "    for r in distinct:\n",
    "        node_frequency[r]+=1\n",
    "def router_traversal_plotter(node_frequency):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.bar(node_frequency.keys(),node_frequency.values())\n",
    "    a=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "    plt.xticks(a,a)\n",
    "    plt.xlabel(\"Router Index\")\n",
    "    plt.ylabel(\"Usage or Traversal Frequency\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afd397",
   "metadata": {},
   "source": [
    "##### Plotting Function Caller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df71bc8",
   "metadata": {},
   "source": [
    "Call the Below after running the appropriate algorithm driver code for the plots. Uncomment the appropriate line for the required plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc704721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_tracker_plotter(flow_tracker)\n",
    "# rejection_plotter(rejection,IEP,PAIR)\n",
    "#link_user_plotter(link_user)\n",
    "#link_user_by_IEP_plotter(link_user_by_IEP)\n",
    "# path_length_plotter(path_length,IEP)\n",
    "# max_flow_decrease_plotter(max_flow_tracker,IEP)\n",
    "#router_traversal_plotter(node_traversal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010cdc7e",
   "metadata": {},
   "source": [
    "##### Comparison Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_db={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8747c0e9",
   "metadata": {},
   "source": [
    "##### MIRA DRIVER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]\n",
    "G_copy=G.copy()\n",
    "G_list_MIRA=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "for demand in range(4000):\n",
    "    G_copy,aaaa,R=MIRA(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand])\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP)\n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_MIRA.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        accepted+=1\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "        \n",
    "print(\"MIRA\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "comparison_db[\"MIRA\"]={}\n",
    "comparison_db[\"MIRA\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"MIRA\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"MIRA\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"MIRA\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"MIRA\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"MIRA\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec69e31",
   "metadata": {},
   "source": [
    "##### MHA DRIVER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_copy=G.copy()\n",
    "G_list_MHA=[]\n",
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity']\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "for demand in range(4000):\n",
    "    G_copy,R=MHA(G_copy.copy(),IEP[PAIR[demand]],DEMAND[demand])\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP)\n",
    "    if R==0:\n",
    "        \n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_MHA.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        accepted+=1\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "        \n",
    "print(\"MHA\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "comparison_db[\"MHA\"]={}\n",
    "comparison_db[\"MHA\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"MHA\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"MHA\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"MHA\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"MHA\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"MHA\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_copy=G.copy()\n",
    "G_list_MHA=[]\n",
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity']\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "for demand in range(4000):\n",
    "    G_copy,R=MHA(G_copy.copy(),IEP[PAIR[demand]],DEMAND[demand])\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP)\n",
    "    if R==0:\n",
    "        \n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_MHA.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        accepted+=1\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "        \n",
    "print(\"MHA\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "comparison_db[\"MHA\"]={}\n",
    "comparison_db[\"MHA\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"MHA\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"MHA\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"MHA\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"MHA\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"MHA\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e890590c",
   "metadata": {},
   "source": [
    "##### IMIRA DRIVER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]\n",
    "G_copy=G.copy()\n",
    "G_list_MIRA=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "for demand in range(4000):\n",
    "    G_copy,aaaa,R=MIRA_1(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand])\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP)\n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_MIRA.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "\n",
    "print(\"I-MIRA\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "comparison_db[\"IMIRA\"]={}\n",
    "comparison_db[\"IMIRA\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"IMIRA\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"IMIRA\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"IMIRA\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"IMIRA\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"IMIRA\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf08691",
   "metadata": {},
   "source": [
    "##### MIH DRIVER CODE T1=8, T2=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]\n",
    "fij={}\n",
    "entire_cap={}\n",
    "for edge in G.edges():\n",
    "    fij[edge]=0\n",
    "    entire_cap[edge]=G[edge[0]][edge[1]]['capacity']\n",
    "G_copy=G.copy()\n",
    "G_list_MIH_8_4=[]\n",
    "T1=8\n",
    "T2=4\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "for demand in range(4000):\n",
    "    G_copy,aaaa,R=MIH(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand],fij,entire_cap,T1,T2)\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP)\n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_MIH_8_4.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "print(\"MIH\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "comparison_db[\"MIH\"]={}\n",
    "comparison_db[\"MIH\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"MIH\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"MIH\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"MIH\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"MIH\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"MIH\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659f062",
   "metadata": {},
   "source": [
    "##### LIOA DRIVER CODE ALPHA=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d6ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def LIOA(G, ab, IEP,D,capacity_dict,demand_dict,alpha):\n",
    "\n",
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]\n",
    "G_copy=G.copy()\n",
    "G_list_LIOA=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "demand_dict={}\n",
    "for edge in G.edges():\n",
    "    demand_dict[edge]=0\n",
    "capacity_dict={}\n",
    "for edge in G.edges():\n",
    "    capacity_dict[edge]=G[edge[0]][edge[1]]['capacity']\n",
    "alpha=0.5\n",
    "for demand in range(4000):\n",
    "    G_copy,aaaa,R=LIOA(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand],capacity_dict,demand_dict,alpha)\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP) \n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_LIOA.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "print(\"LIOA\",alpha)\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "comparison_db[\"LIOA\"]={}\n",
    "comparison_db[\"LIOA\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"LIOA\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"LIOA\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"LIOA\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"LIOA\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"LIOA\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac194f08",
   "metadata": {},
   "source": [
    "##### ILIOA DRIVER CODE alpha=0.5 beta=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]\n",
    "alpha=0.5\n",
    "beta=0.5\n",
    "G_copy=G.copy()\n",
    "G_list_ILIOA=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "demand_dict={}\n",
    "for edge in G.edges():\n",
    "    demand_dict[edge]=0\n",
    "capacity_dict={}\n",
    "for edge in G.edges():\n",
    "    capacity_dict[edge]=G[edge[0]][edge[1]]['capacity']\n",
    "for demand in range(4000):\n",
    "    G_copy,aaaa,R=ILIOA(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand],capacity_dict,demand_dict,alpha,beta)\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP) \n",
    "\n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_ILIOA.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "\n",
    "print(\"ILIOA\",alpha,beta)\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "\n",
    "comparison_db[\"ILIOA\"]={}\n",
    "comparison_db[\"ILIOA\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"ILIOA\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"ILIOA\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"ILIOA\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"ILIOA\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"ILIOA\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892325bc",
   "metadata": {},
   "source": [
    "##### BCRA DRIVER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]\n",
    "G_copy=G.copy()\n",
    "G_list_LIOA=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "demand_dict={}\n",
    "for edge in G.edges():\n",
    "    demand_dict[edge]=0\n",
    "capacity_dict={}\n",
    "for edge in G.edges():\n",
    "    capacity_dict[edge]=G[edge[0]][edge[1]]['capacity']\n",
    "G_copy=G.copy()\n",
    "G_list_BCRA=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "capacity_dict={}\n",
    "for edge in G.edges():\n",
    "    capacity_dict[edge]=G[edge[0]][edge[1]]['capacity']\n",
    "for demand in range(10000):\n",
    "    G_copy,aaaa,R=BCRA(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand],capacity_dict)\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP) \n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_BCRA.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "\n",
    "print(\"BCRA\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "\n",
    "comparison_db[\"BCRA\"]={}\n",
    "comparison_db[\"BCRA\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"BCRA\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"BCRA\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"BCRA\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"BCRA\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"BCRA\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b050e4e0",
   "metadata": {},
   "source": [
    "#### RNLC DRIVER CODE C=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for C in [0.0001,0.001,0.01,0.1,1,2,3,4,5,6,7,8,9,10,100,1000,10000]:\n",
    "#def RNLC(G, ab, IEP,D,C):\n",
    "\n",
    "\n",
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]\n",
    "G_copy=G.copy()\n",
    "G_list_RNLC=[]\n",
    "accepted=0\n",
    "C=1\n",
    "not_accepted=0\n",
    "for demand in range(4000):\n",
    "    G_copy,aaaa,R=RNLC(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand],C)\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP) \n",
    "\n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_RNLC.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "\n",
    "print(\"RNLC\",C)\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "comparison_db[\"RNLC\"]={}\n",
    "comparison_db[\"RNLC\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"RNLC\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"RNLC\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"RNLC\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"RNLC\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"RNLC\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a6eb2",
   "metadata": {},
   "source": [
    "##### MAX RC MIN F driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4965e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def RCF(G, ab, IEP,D,capacity_dict,demand_dict):\n",
    "   \n",
    "\n",
    "    \n",
    "#for k in [0.00001,0.0001,0.001,0.01,0.1,1,2,3,4,5,6,7,8,9,10,100,1000,10000,100000]:\n",
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]    \n",
    "G_copy=G.copy()\n",
    "G_list_RCF=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "demand_dict={}\n",
    "for edge in G.edges():\n",
    "    demand_dict[edge]=0\n",
    "capacity_dict={}\n",
    "for edge in G.edges():\n",
    "    capacity_dict[edge]=G[edge[0]][edge[1]]['capacity']\n",
    "for demand in range(10000):\n",
    "#     try:\n",
    "    G_copy,aaaa,R=RCF(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand],capacity_dict,demand_dict)\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP) \n",
    "\n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_RCF.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "\n",
    "        \n",
    "print(\"Max Rc Min F\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "\n",
    "comparison_db[\"RCF\"]={}\n",
    "comparison_db[\"RCF\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"RCF\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"RCF\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"RCF\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"RCF\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"RCF\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ee92a",
   "metadata": {},
   "source": [
    "##### NHMI DRIVER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88101b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]    \n",
    "T1=10\n",
    "T2=100\n",
    "import numpy as np\n",
    "G_copy=G.copy()\n",
    "G_list_NMIH=[]\n",
    "fij={}\n",
    "entire_cap={}\n",
    "for edge in G.edges():\n",
    "    fij[edge]=0\n",
    "    entire_cap[edge]=G[edge[0]][edge[1]]['capacity']\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "for demand in range(4000):\n",
    "\n",
    "        G_copy,aaaa,R=NMIH(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand],entire_cap,T1,T2)\n",
    "        flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "        max_flow_decrease(G_copy,max_flow_tracker,IEP) \n",
    "        if R==0:\n",
    "            not_accepted+=1\n",
    "            rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "        else:\n",
    "            G_list_NMIH.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "            accepted+=1\n",
    "            link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "            path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "            router_traversal(node_traversal,R)\n",
    "\n",
    "\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"NMHI\",T1,T2)\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "comparison_db[\"NHMI\"]={}\n",
    "comparison_db[\"NHMI\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"NHMI\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"NHMI\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"NHMI\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"NHMI\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"NHMI\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5bc976",
   "metadata": {},
   "source": [
    "##### LEX MAX DRIVER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee0edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]    \n",
    "\n",
    "G_copy=G.copy()\n",
    "G_list_LEXMAX=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "delta=1\n",
    "for demand in range(10000):\n",
    "    G_copy,aaaa,R=LEXMAX(G_copy.copy(),IEP[PAIR[demand]],IEP,DEMAND[demand],delta)\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP) \n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_LEXMAX.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "        \n",
    "print(\"LEXMAX\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "comparison_db[\"LEXMAX\"]={}\n",
    "comparison_db[\"LEXMAX\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"LEXMAX\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"LEXMAX\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"LEXMAX\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"LEXMAX\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"LEXMAX\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46511d0a",
   "metadata": {},
   "source": [
    "#### WSP DRIVER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19699c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "G_copy=G.copy()\n",
    "G_list_WSP=[]\n",
    "critical_progress_WSP=[]\n",
    "max_flow_progress_WSP=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "demand_dict={}\n",
    "\n",
    "for demand in range(4000):\n",
    "    G_copy,aaaa,R=WSP(G_copy.copy(),IEP[PAIR[demand]],DEMAND[demand])\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP) \n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "    else:\n",
    "        G_list_WSP.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "\n",
    "print(\"WSP\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "comparison_db[\"WSP\"]={}\n",
    "comparison_db[\"WSP\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"WSP\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"WSP\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"WSP\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"WSP\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"WSP\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197009b0",
   "metadata": {},
   "source": [
    "##### SWP DRIRVER CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flow_tracker={}\n",
    "max_flow_tracker={}\n",
    "node_traversal={}\n",
    "for node in G.nodes():\n",
    "    node_traversal[node]=0\n",
    "for edge in G.edges():\n",
    "    flow_tracker[edge]=[G[edge[0]][edge[1]]['capacity'],]\n",
    "for iep in IEP:\n",
    "    max_flow_tracker[tuple(iep)]=[]\n",
    "    max_flow_tracker[tuple(iep)].append(nx.maximum_flow(G,iep[0],iep[1])[0])\n",
    "rejection={}\n",
    "for iep in IEP:\n",
    "    rejection[tuple(iep)]=0\n",
    "link_user={}\n",
    "for edge in G.edges():\n",
    "    link_user[edge]=0\n",
    "link_user_by_IEP={}\n",
    "for iep in IEP:\n",
    "    link_user_by_IEP[tuple(iep)]=link_user.copy()    \n",
    "path_length={}\n",
    "for iep in IEP:\n",
    "    path_length[tuple(iep)]=[]    \n",
    "    \n",
    "G_copy=G.copy()\n",
    "G_list_SWP=[]\n",
    "accepted=0\n",
    "not_accepted=0\n",
    "demand_dict={}\n",
    "\n",
    "for demand in range(4000):\n",
    "    G_copy,aaaa,R=SWP(G_copy.copy(),IEP[PAIR[demand]],DEMAND[demand])\n",
    "    flow_decrease_on_links(flow_tracker,R,G_copy)\n",
    "    max_flow_decrease(G_copy,max_flow_tracker,IEP) \n",
    "    if R==0:\n",
    "        not_accepted+=1\n",
    "        rejection[tuple(IEP[PAIR[demand]])]+=1\n",
    "\n",
    "\n",
    "    else:\n",
    "        G_list_SWP.append((G_copy.copy(),R,IEP[PAIR[demand]],DEMAND[demand]))\n",
    "        accepted+=1\n",
    "        link_usage(link_user,link_user_by_IEP,R,G,IEP[PAIR[demand]])\n",
    "        path_length[tuple(IEP[PAIR[demand]])].append(len(R))\n",
    "        router_traversal(node_traversal,R)\n",
    "\n",
    "for keys in path_length.keys():\n",
    "    path_length[keys]=sum(path_length[keys])/len(path_length[keys])\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"SWP\")\n",
    "print(\"ACCEPTED!!!!\",accepted)\n",
    "print(\"NOT ACCEPTED!!!\",not_accepted)\n",
    "\n",
    "\n",
    "\n",
    "comparison_db[\"SWP\"]={}\n",
    "comparison_db[\"SWP\"][\"FLOWLINKDECREASE\"]=flow_tracker\n",
    "comparison_db[\"SWP\"][\"REJECTION\"]=rejection\n",
    "comparison_db[\"SWP\"][\"LINKUSAGE\"]=link_user\n",
    "comparison_db[\"SWP\"][\"LINKUSAGEBYIEP\"]=link_user_by_IEP\n",
    "comparison_db[\"SWP\"][\"PATHLENGTH\"]=path_length\n",
    "comparison_db[\"SWP\"][\"MAXFLOWDECREASE\"]=max_flow_tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_list=list(comparison_db.keys())\n",
    "metric_list=list(comparison_db[\"MIRA\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6bbd48",
   "metadata": {},
   "source": [
    "##### Comparative Rejection Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejection_list={}\n",
    "for alg in algorithm_list:\n",
    "    comparison_db[alg][\"TOTALREJECTION\"]=sum(comparison_db[alg][\"REJECTION\"].values())\n",
    "    rejection_list[alg]=comparison_db[alg][\"TOTALREJECTION\"]\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(rejection_list.keys(),rejection_list.values())\n",
    "plt.xlabel(\"Algorithm\")\n",
    "plt.ylabel(\"Rejection Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03e44c",
   "metadata": {},
   "source": [
    "##### PATH LENGTH PLOTTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlength_list={}\n",
    "for alg in algorithm_list:\n",
    "    comparison_db[alg][\"TOTALPATHLENGTH\"]=sum(comparison_db[alg][\"PATHLENGTH\"].values())/4\n",
    "    rejection_list[alg]=comparison_db[alg][\"TOTALPATHLENGTH\"]\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(rejection_list.keys(),rejection_list.values())\n",
    "plt.xlabel(\"Algorithm\")\n",
    "plt.ylabel(\"PATH LENGTH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d792ab9",
   "metadata": {},
   "source": [
    "##### LINK USAGE PLOTTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5f6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0681187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"linkusage.csv\",\"w\") as csvf:\n",
    "    writer=csv.writer(csvf)\n",
    "    csv_list=[\"ALGORITHM\"]\n",
    "    for l in comparison_db[alg][\"LINKUSAGE\"].keys():\n",
    "        csv_list.append(str(l))\n",
    "    writer.writerow(csv_list)\n",
    "    for alg in algorithm_list:\n",
    "        #print(list(comparison_db[alg][\"LINKUSAGE\"].values()))\n",
    "        temp=[alg]\n",
    "        for v in list(comparison_db[alg][\"LINKUSAGE\"].values()):\n",
    "            temp.append(v)\n",
    "            \n",
    "        writer.writerow(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f468c82",
   "metadata": {},
   "source": [
    "##### Max Flow Decrease Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d4dea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "alg=\"MIRA\"\n",
    "for alg in algorithm_list:\n",
    "    comparison_db[alg][\"TOTALMAXFLOWDECREASE\"]=0\n",
    "    mf_list=[]\n",
    "    total_mf_list={}\n",
    "    for alg in algorithm_list:\n",
    "        mf_list=[]\n",
    "        for keys,values in comparison_db[alg][\"MAXFLOWDECREASE\"].items():\n",
    "            mf_list.append(values)\n",
    "        temp=[]\n",
    "        index=0\n",
    "        t_val=0\n",
    "        for i in range(4000):\n",
    "            for lst in mf_list:\n",
    "                t_val+=lst[i]\n",
    "                #print(al,t_val,i)\n",
    "            temp.append(t_val)\n",
    "            t_val=0\n",
    "        total_mf_list[alg]=temp\n",
    "        \n",
    "for alg in algorithm_list:\n",
    "    plt.plot(range(0,4000),total_mf_list[alg])\n",
    "plt.legend(algorithm_list)\n",
    "plt.xlabel(\"Instance\")\n",
    "plt.ylabel(\"Sum of Maxflow Value\")\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2eb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f62416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513046ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in algorithm_list:\n",
    "    print(alg,comparison_db[alg][\"TOTALREJECTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "DEMAND=[]\n",
    "PAIR=[]\n",
    "for d in range(10000):\n",
    "    DEMAND.append(random.randint(1,4))\n",
    "    PAIR.append(random.randint(0,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face66bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
